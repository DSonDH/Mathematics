# 1. 측정과 자료의 기초

## 1.1 변수(variable)와 관측값(observation)
* **변수(variable)**: 관측/측정되는 특성으로, 값이 달라질 수 있는 대상.
    * 표기 예: 한 개인(또는 단위) $i$의 변수 $X$ 값은 $x_i$.
* **관측단위(unit of analysis)**: 개인, 가구, 기업, 국가, 실험 대상 등 “값이 기록되는 대상”.
* **데이터 구조(데이터 행렬)**  
    * $n$개 관측단위, $p$개 변수일 때 데이터를 $n \times p$ 행렬 $\mathbf{X}$로 표현:
        $$
        \mathbf{X}= \begin{bmatrix}
        x_{11} & x_{12} & \cdots & x_{1p} \\
        x_{21} & x_{22} & \cdots & x_{2p} \\
        \vdots & \vdots & \ddots & \vdots \\
        x_{n1} & x_{n2} & \cdots & x_{np}
        \end{bmatrix}
        $$
    * 행(row): 관측단위, 열(column): 변수.

## 1.2 질적 변수 vs 양적 변수
* **질적 변수(categorical / qualitative variable)**: 범주로 구분되는 변수.
    * 예: 성별, 지역, 제품군, 혈액형
    * 분석에서 흔히 **더미변수(dummy variable)**로 변환(예: 범주 $k$개 → $k-1$개 지시변수).
        * 예: “서울 여부” $D_i \in \{0,1\}$
* **양적 변수(quantitative / numerical variable)**: 수치로 크기/양을 나타내는 변수.
    * 예: 키, 점수, 소득, 온도
    * 연산(덧셈/평균/비율 등)과 해석이 상대적으로 자연스러움.

## 1.3 측정수준(level of measurement)과 가능한 연산
측정수준은 “숫자가 무엇을 의미하는가”를 결정하며, 허용되는 연산/해석 범위를 좌우함.

* **명목척도(nominal scale)**: 이름/범주만 구분(순서 없음)
    * 예: 지역 {A,B,C}, 혈액형 {A,B,O,AB}
    * 가능한 것: 빈도 비교, 최빈값, 비율
    * 주의: 숫자로 코딩해도 크기 비교(>, <)는 의미 없음.
* **서열척도(ordinal scale)**: 순서만 의미(간격은 불명확)
    * 예: 만족도(1~5), 등급(A/B/C)
    * 가능한 것: 중앙값, 분위수, 순위 기반 분석(스피어만 등)
    * 주의: $5-4$와 $3-2$의 “차이”를 동일 간격으로 해석하면 위험.
* **등간척도(interval scale)**: 간격이 동일(0이 절대적 의미는 아님)
    * 예: 섭씨/화씨 온도
    * 특징: 차이는 의미 있으나 비율은 부적절  
        * 예: 섭씨에서 $20^\circ C$가 $10^\circ C$의 “2배로 따뜻”하다고 말할 수 없음.
    * 선형 변환: $Y = aX + b$ (단, $a>0$)가 의미를 보존.
* **비율척도(ratio scale)**: 간격 동일 + 절대적 0 존재(비율 비교 가능)
    * 예: 길이, 무게, 나이, 시간(지속시간), 소득(0의 의미가 자연스러운 경우)
    * 비율 해석 가능: $\frac{x_1}{x_2}$가 의미 있음(예: 10kg은 5kg의 2배)

## 1.4 자료 유형: 이산형 vs 연속형
* **이산형 자료(discrete data)**: 셀 수 있는 값(대개 정수)
    * 예: 방문 횟수, 결함 개수, 합격자 수
    * 표기: $X \in \{0,1,2,\dots\}$
* **연속형 자료(continuous data)**: 연속적인 구간의 값
    * 예: 시간, 길이, 온도, 농도
    * 표기: $X \in \mathbb{R}$ (구간 단위로 확률/비율을 다루는 경우가 많음)
* **실무 메모**: 측정 도구의 해상도(예: 소수점 반올림) 때문에 연속 변수가 “이산처럼” 기록될 수 있음.

## 1.5 모집단과 표본, 모수와 통계량
* **모집단(population)**: 관심 있는 전체 집합(크기 $N$).
* **표본(sample)**: 모집단에서 관측한 일부(크기 $n$).
* **모수(parameter)**: 모집단의 특성(예: 평균 $\mu$, 분산 $\sigma^2$, 비율 $p$).
* **통계량(statistic)**: 표본으로 계산한 값(예: $\bar{x}$, $s^2$, $\hat{p}$).
    * 예: 표본평균
        $$\bar{x} = \frac{1}{n}\sum_{i=1}^{n} x_i$$
    * 예: 표본비율(성공=1로 코딩한 더미 $D_i$의 평균)
        $$\hat{p} = \frac{1}{n}\sum_{i=1}^{n} D_i$$

## 1.6 표본추출(sampling)과 대표성/편향
표본추출은 **대표성(representativeness)**을 좌우하며, 편향(bias)이 생기면 추론이 왜곡될 수 있음.

* **단순임의추출(simple random sampling, SRS)**  
    * 모든 개체가 동일 확률로 선택.
    * 복원추출이면 각 개체 선택확률 $P(선택)=\frac{1}{N}$로 동일(개념적으로).
* **층화추출(stratified sampling)**  
    * 모집단을 동질적인 **층(stratum)**으로 나눈 뒤 각 층에서 표본을 추출.
    * 장점: 층 내 변동이 작으면 추정 정밀도 향상.
* **군집추출(cluster sampling)**  
    * 모집단을 **군집(cluster)**으로 묶고 군집을 뽑아 조사(군집 내 전수조사 또는 일부추출).
    * 장점: 비용/현장조사 효율.
    * 주의: 군집 내 유사성이 크면(상관이 크면) 유효 표본정보가 줄 수 있음.

* **표본오차(sampling error)**: 표본이 우연히 달라져 생기는 차이(“랜덤 오차”).
* **비표본오차(non-sampling error)**: 측정오류, 무응답, 기록 오류 등(표본을 늘려도 남을 수 있음).


# 2. 신뢰도와 타당도

측정은 **관측값(observed score)**이 항상 “참값(true score)”과 “오차(error)”를 포함한다는 점에서 출발함(고전검사이론, CTT).
$$
X = T + E
$$
* $X$: 관측값, $T$: 참점수(진짜 수준), $E$: 측정오차
* 기본 가정(CTT): $E(T)=0$, $Cov(T,E)=0$ (오차는 평균 0이고 참점수와 독립)

## 2.1 신뢰도(reliability): 일관성/재현성
신뢰도는 “같은 대상을 반복/유사 조건에서 측정했을 때 얼마나 비슷한 결과가 나오는가”를 뜻함.  
CTT에서 신뢰도는 **관측값 분산 중 참점수 분산의 비율**로 정의됨.
$$
\rho_{XX'}=\frac{Var(T)}{Var(X)} = 1-\frac{Var(E)}{Var(X)}
$$
* 해석: 오차 분산이 작을수록(정밀할수록) 신뢰도는 커짐.
* 주의: 신뢰도는 **측정도구의 고정 속성**이 아니라, **대상 집단/상황**에 따라 달라질 수 있음(분산이 달라지면 신뢰도도 변함).

### (1) 검사-재검사 신뢰도(test–retest reliability)
시간 간격을 두고 동일 검사를 반복 시행하여 상관을 본다.
* 절차: 1차 점수 $X_1$, 2차 점수 $X_2$ 측정 → $r(X_1, X_2)$
* 장점: 시간적 안정성 평가
* 한계: 학습효과/기억효과, 실제 변화(성장/치료 등)와 구분 필요

### (2) 동형검사(평행형) 신뢰도(parallel-form reliability)
동일한 구성개념을 측정하는 **두 개의 유사한 검사형** $A,B$의 일치도를 본다.
* 지표: $r(X_A, X_B)$
* 전제(강한 형태): 두 검사형이 난이도/분산/측정오차가 유사(평행검사 가정)

### (3) 반분 신뢰도(split-half reliability)와 Spearman–Brown 보정
문항을 둘로 나눠(예: 홀/짝) 두 반쪽 점수의 상관 $r_{1/2}$을 구한 뒤, 전체 검사 길이에 대한 신뢰도로 보정.
$$
r_{SB}=\frac{2r_{1/2}}{1+r_{1/2}}
$$
* 문항 분할 방식에 따라 값이 달라질 수 있음 → 내적일관성 지표(알파 등)와 함께 사용

### (4) 내적일관성(internal consistency)
문항들이 같은 개념을 얼마나 일관되게 재는지 평가(한 번의 시행으로 추정).

#### 크론바흐 알파(Cronbach’s alpha)
문항 수 $k$, 각 문항 분산 $\sigma_i^2$, 총점 분산 $\sigma_X^2$일 때:
$$
\alpha=\frac{k}{k-1}\left(1-\frac{\sum_{i=1}^{k}\sigma_i^2}{\sigma_X^2}\right)
$$
* 해석(실무적): 값이 클수록 내적일관성이 높은 경향(단, “좋다/나쁘다”의 절대 기준은 맥락 의존)
* 주의:
    * 문항 수 $k$가 많아지면 $\alpha$가 커질 수 있음(길이 효과).
    * 단일차원(unidimensional)이라고 자동으로 보장하지 않음(요인구조 점검 필요).

### (5) 평가자 간 신뢰도(inter-rater reliability)
사람이 채점/분류하는 측정에서 평가자 간 일치도를 본다.
* 범주형 분류: **Cohen’s kappa**
    $$
    \kappa=\frac{p_o-p_e}{1-p_e}
    $$
    * $p_o$: 관측 일치율, $p_e$: 우연 일치 기대값
* 연속형 점수/평정: **ICC(intraclass correlation coefficient)** 등을 사용(설계에 따라 유형 선택).

## 2.2 측정오차(measurement error)와 표준오차(SEM)
측정오차는 무작위 오차(random error)와 체계적 오차(systematic error)로 구분 가능.
* **무작위 오차**: 우연적 요인(컨디션, 환경 소음 등) → 신뢰도 저하
* **체계적 오차**: 특정 방향으로 치우치는 요인(문항 편향, 장비 교정 문제 등) → 타당도까지 훼손 가능

### 표준오차(standard error of measurement, SEM)
관측점수의 “측정 정밀도”를 점수 단위로 표현.
표본 표준편차 $s_X$와 신뢰도 $r_{xx}$를 이용해:
$$
SEM = s_X\sqrt{1-r_{xx}}
$$
* 활용: 한 개인의 점수 주변 “오차 범위”를 제시할 때 사용(점수 해석의 불확실성 표현).
* 예(구간 표현 형태): $X \pm z\cdot SEM$ (정규성 가정을 두는 경우가 많음)

## 2.3 타당도(validity): 의도한 개념을 제대로 재는가
타당도는 “측정이 목표한 구성개념을 얼마나 적절히 반영하는가”에 대한 근거의 집합.  
중요 원칙: **신뢰도는 타당도의 필요조건**(대체로), 그러나 **신뢰도만 높다고 타당도가 보장되지는 않음**.

### (1) 내용타당도(content validity)
문항이 목표 영역을 충분히 대표하는지(전문가 판단, 청사진/블루프린트 기반).
* 방법: 전문가 패널 검토, 문항-목표 매핑, 문항 커버리지 점검
* 주의: 통계치 하나로 끝내기 어렵고, 근거(절차/기준)를 문서화하는 것이 핵심

### (2) 준거타당도(criterion validity)
외부 기준(성과, 진단, 실제 행동 등)과의 관련성.
* **예측타당도(predictive validity)**: 미래 준거 $Y_{future}$와의 관련
    * 예: 입학시험 점수 $X$와 이후 학업성취 $Y$의 상관/회귀
* **공인타당도(concurrent validity)**: 현재 준거 $Y_{now}$와의 관련
    * 예: 간이검사 $X$와 표준검사 $Y$의 동시 측정 상관

### (3) 구성타당도(construct validity)
이론적 구성개념을 잘 반영하는지에 대한 증거(가장 포괄적).
* **수렴타당도(convergent validity)**: 같은/유사 구성개념 측정치와 높은 관련
    * 예: $r(X, Z)\uparrow$ (둘 다 불안 측정)
* **변별타당도(discriminant validity)**: 다른 구성개념 측정치와 낮은 관련
    * 예: $r(X, W)\downarrow$ (불안 vs 지능)
* **요인타당도(factorial validity)**: 탐색적/확인적 요인분석으로 문항 구조가 이론과 부합하는지 확인
    * 예: 단일요인/다요인 구조, 문항 적재량(loading) 패턴 점검
* **다특성-다방법(MTMM)**: 특성(trait)과 방법(method)을 분리해 타당도 근거를 축적

## 2.4 신뢰도 vs 타당도: 관계와 실무 체크리스트
* 신뢰도는 “일관성”, 타당도는 “정확성(적합성)”에 가깝다.
* 실무 점검(요약):
    1. 측정 목적/구성개념 정의(운영적 정의 포함)
    2. 문항 설계(내용 대표성 확보) → 내용타당도 근거
    3. 파일럿/문항분석(난이도, 변별도, 응답분포, 결측/편향)
    4. 신뢰도 추정(재검사/평행형/알파/ICC 등 맥락에 맞게)
    5. 준거 및 구성 타당도 근거 축적(상관, 회귀, 요인분석 등)
    6. 점수 해석 시 불확실성(SEM)과 한계(표본/상황 의존성) 명시


# 3. 기술통계(descriptive statistics)

기술통계는 자료를 **요약(표·수치)**하고 **시각화(그래프)**하여 분포의 특징(중심, 퍼짐, 형태, 이상치)을 빠르게 파악하는 단계다.  
표본 자료 $\{x_1,\dots,x_n\}$를 기본 대상으로 설명하며, 모수(모집단 특성) 추정·추론으로 넘어가기 전 “데이터가 어떻게 생겼는지”를 점검한다.

## 3.1 빈도분석(frequency analysis)

### 3.1.1 도수분포표(frequency table)
자료값(또는 구간)별로 빈도를 요약한 표.

* **도수(절대도수)**: 값 $x$가 나타난 횟수 $f(x)$  
* **상대도수(relative frequency)**: 전체 대비 비율
    $$
    r(x)=\frac{f(x)}{n}
    $$
* **백분율(percentage)**: $100\times r(x)$ (%)
* **누적도수(cumulative frequency)**: 어떤 값/구간까지의 누적 합
    $$
    F(x)=\sum_{t\le x} f(t),\qquad R(x)=\sum_{t\le x} r(t)=\frac{F(x)}{n}
    $$

#### (1) 범주형 자료
범주별 빈도, 상대도수, 누적(순서가 있는 범주면) 등을 표로 만든다.

#### (2) 연속형 자료(구간화, class interval)
연속형 자료는 보통 구간(bin)으로 나눠 빈도를 센다.

* 구간 수 $k$의 경험칙(참고): $k\approx \sqrt{n}$ 또는 Sturges 규칙 $k\approx 1+\log_2 n$
* 구간폭(width) $h$ 예: $h=\dfrac{\max-\min}{k}$

> 메모: 구간폭/구간 시작점에 따라 히스토그램 모양이 달라질 수 있으므로, 여러 설정을 비교해 보는 것이 좋다.

### 3.1.2 시각화
* **막대그래프(bar chart)**: 범주형 빈도 비교(막대 간 간격 존재)
* **원그래프(pie chart)**: 비율 표현(범주 수가 적을 때만 권장)
* **히스토그램(histogram)**: 연속형의 구간 빈도(막대 간 간격 없음)
    * 구간폭이 동일하면 막대 높이 $\propto$ 빈도
    * 구간폭이 다르면 **면적**이 빈도에 비례하도록 “밀도”로 그리기도 함
* **도수다각형(frequency polygon)**: 구간 중간점과 빈도를 선으로 연결
* **줄기-잎 그림(stem-and-leaf)**: 소규모 자료에서 원자료 보존하면서 분포 확인
* **누적도수곡선(ogive)**: 누적상대도수 $R(x)$를 시각화

## 3.2 집중경향치(central tendency)

분포의 “대표 위치”를 한 값으로 요약한다. 이상치(outlier) 유무와 자료의 분포 형태에 따라 적절한 지표가 달라진다.

### 3.2.1 평균(mean)
#### (1) 산술평균(arithmetic mean)
표본평균:
$$
\bar{x}=\frac{1}{n}\sum_{i=1}^{n} x_i
$$

* 장점: 수학적 성질이 좋고(추론에서 핵심), 전체 정보를 반영
* 단점: 극단치에 민감(예: 소득 분포)

#### (2) 가중평균(weighted mean)
가중치 $w_i\ge 0$가 있을 때:
$$
\bar{x}_w=\frac{\sum_{i=1}^{n} w_i x_i}{\sum_{i=1}^{n} w_i}
$$`
(예: 학점 평균, 표본가중치가 있는 조사자료)

#### (3) 기하평균(geometric mean)
성장률/비율의 평균(양수 자료)에서 자주 사용:
$$
G=\left(\prod_{i=1}^{n} x_i\right)^{1/n}
\;=\;\exp\left(\frac{1}{n}\sum_{i=1}^{n}\ln x_i\right)
$$

#### (4) 조화평균(harmonic mean)
속도처럼 “분모에 있는 값”의 평균에 유용(양수 자료):
$$
H=\frac{n}{\sum_{i=1}^{n} \frac{1}{x_i}}
$$

### 3.2.2 중앙값(median)
자료를 오름차순 정렬한 값 $x_{(1)}\le \cdots \le x_{(n)}$에 대해

* $n$이 홀수면
    $$
    \tilde{x}=x_{((n+1)/2)}
    $$
* $n$이 짝수면(보통 두 가운데 값의 평균)
    $$
    \tilde{x}=\frac{x_{(n/2)}+x_{(n/2+1)}}{2}
    $$

* 장점: 이상치에 강건(robust)
* 연관: **사분위수**도 “중앙값의 일반화(분위수)”로 볼 수 있음

### 3.2.3 최빈값(mode)
가장 자주 관측되는 값(또는 구간). 범주형 자료의 대표값으로 특히 유용.

* 연속형은 구간화한 뒤 “최빈구간(modal class)”을 말하는 경우가 많다.
* 분포가 다봉형이면 최빈값이 여러 개일 수 있다.

### 3.2.4 절사평균(trimmed mean)
양 끝 일부(예: 각 10%)를 제거하고 평균을 계산해 극단치 영향을 줄인다.  
예: $g$개씩 양끝을 제거하면
$$
\bar{x}_{trim}=\frac{1}{n-2g}\sum_{i=g+1}^{n-g} x_{(i)}
$$

## 3.3 분산도(measures of variability)

중심 주변으로 데이터가 얼마나 퍼져 있는지(흩어짐)를 요약한다.

### 3.3.1 범위(range)
$$
Range=\max(x_i)-\min(x_i)
$$
* 매우 간단하지만 극단치에 크게 좌우됨.

### 3.3.2 분산(variance)과 표준편차(standard deviation)
#### (1) 표본분산(sample variance)
$$
s^2=\frac{1}{n-1}\sum_{i=1}^{n}(x_i-\bar{x})^2
$$
* $n-1$로 나누는 이유: 모집단분산 $\sigma^2$의 **불편추정량**이 되도록 하는 보정(Bessel’s correction)

#### (2) 표본표준편차(sample standard deviation)
$$
s=\sqrt{s^2}
$$
* 원 단위로 해석 가능(예: cm, 점수)

#### (3) 모집단분산(population variance) 표기(참고)
모집단 전체를 알고 있을 때:
$$
\sigma^2=\frac{1}{N}\sum_{i=1}^{N}(x_i-\mu)^2,\qquad \sigma=\sqrt{\sigma^2}
$$

### 3.3.3 사분위수(quartile)와 사분위범위(IQR)
정렬값 $x_{(i)}$에서

* $Q_2$: 중앙값(50% 분위수)
* $Q_1$: 25% 분위수, $Q_3$: 75% 분위수
* **사분위범위**
    $$
    IQR=Q_3-Q_1
    $$
    중앙 50%의 퍼짐을 측정하며 이상치에 강건하다.

#### (1) 박스플롯(box plot)과 이상치 규칙(실무에서 흔함)
* 하한/상한 경계(가벼운 이상치 기준):
    $$
    Lower=Q_1-1.5\cdot IQR,\qquad Upper=Q_3+1.5\cdot IQR
    $$
* 이 범위를 벗어나면 이상치 후보로 표시(“오류”로 단정하진 말고 원인 확인).

### 3.3.4 평균절대편차(MAD, median absolute deviation) (강건 지표)
중앙값 기준 절대편차의 중앙값:
$$
MAD=\text{median}\left(\,|x_i-\tilde{x}|\,\right)
$$
* 이상치가 있는 자료에서 $s$보다 안정적으로 퍼짐을 요약하는 데 유용.

### 3.3.5 변동계수(coefficient of variation, CV)
서로 단위/규모가 다른 변수의 상대적 변동 비교에 사용(평균이 양수이고 0에 가깝지 않을 때 권장).
$$
CV=\frac{s}{\bar{x}}
$$

## 3.4 (추가) 분포의 형태: 왜도·첨도, 표준화

### 3.4.1 왜도(skewness)와 해석
* 오른쪽 꼬리가 길면(큰 값 방향으로 꼬리) **양(+)의 왜도**, 왼쪽이 길면 **음(-)의 왜도**
* 실무에서는 수치보다 히스토그램/박스플롯으로 형태를 함께 확인하는 것이 안전

(참고: 대표적인 표본 왜도 계수 중 하나)
$$
g_1=\frac{1}{n}\sum_{i=1}^{n}\left(\frac{x_i-\bar{x}}{s}\right)^3
$$

### 3.4.2 첨도(kurtosis) (참고)
꼬리의 두꺼움/뾰족함을 요약하려는 지표.
$$
g_2=\frac{1}{n}\sum_{i=1}^{n}\left(\frac{x_i-\bar{x}}{s}\right)^4-3
$$

### 3.4.3 표준화(z-score)
서로 다른 척도의 값을 비교하거나 이상치를 점검할 때 사용.
$$
z_i=\frac{x_i-\bar{x}}{s}
$$
* 경험적으로 $|z|\ge 3$ 근처는 극단값 후보로 점검하는 경우가 많음(정규성 가정이 강하지 않더라도 “점검 신호”로 유용).

## 3.5 (요약) 어떤 지표를 언제 쓰나
* **대칭적이고 이상치가 적음**: $\bar{x}$, $s$
* **비대칭/이상치 존재 가능**: $\tilde{x}$, $IQR$, $MAD$, 절사평균
* **비율·성장률**: 기하평균 $G$
* **속도/단가처럼 분모형 평균**: 조화평균 $H$
* **규모가 다른 변수 비교**: 변동계수 $CV$


# 4. 확률과 분포

확률 파트의 목표는 (1) 사건의 확률을 계산하는 규칙, (2) 확률변수의 분포를 요약하는 함수(PMF/PDF/CDF), (3) 평균·분산 같은 요약치와 대표 분포들을 익혀 이후 추론(표본분포, 신뢰구간, 가설검정)으로 연결하는 것이다.

## 4.1 확률의 기초: 표본공간, 사건, 공리

* **표본공간(sample space)** $\Omega$: 가능한 모든 결과의 집합  
* **사건(event)** $A \subseteq \Omega$: 관심 있는 결과들의 부분집합
* **확률(probability)** $P(A)$: 사건 $A$가 일어날 가능성(0~1)

### 4.1.1 확률의 공리(axioms)
확률함수 $P(\cdot)$는 다음을 만족한다.

1. (비음성) $P(A)\ge 0$
2. (정규화) $P(\Omega)=1$
3. (가법성) 서로소 사건 $A\cap B=\varnothing$이면  
    $$P(A\cup B)=P(A)+P(B)$$

### 4.1.2 자주 쓰는 성질
* 여사건(complement): $A^c=\Omega\setminus A$  
  $$P(A^c)=1-P(A)$$
* 포함-배제(2개 사건):  
  $$P(A\cup B)=P(A)+P(B)-P(A\cap B)$$

## 4.2 조건부확률, 독립, 베이즈 정리

### 4.2.1 조건부확률(conditional probability)
사건 $B$가 일어났다고 “조건”을 걸었을 때 $A$의 확률:
$$
P(A\mid B)=\frac{P(A\cap B)}{P(B)}\qquad (P(B)>0)
$$

### 4.2.2 곱셈법칙(multiplication rule)
$$
P(A\cap B)=P(A\mid B)P(B)=P(B\mid A)P(A)
$$

연쇄 형태(3개 사건 예):
$$
P(A\cap B\cap C)=P(A)\,P(B\mid A)\,P(C\mid A\cap B)
$$

### 4.2.3 독립(independence)
두 사건 $A,B$가 독립이면 다음이 동치:
$$
P(A\cap B)=P(A)P(B)\quad \Leftrightarrow \quad P(A\mid B)=P(A)
$$

### 4.2.4 베이즈 정리(Bayes’ theorem)
$$
P(A\mid B)=\frac{P(B\mid A)P(A)}{P(B)}
$$

**전확률법칙**(사건 $\{A_i\}$가 서로소이고 $\cup_i A_i=\Omega$):
$$
P(B)=\sum_i P(B\mid A_i)P(A_i)
$$

따라서
$$
P(A_k\mid B)=\frac{P(B\mid A_k)P(A_k)}{\sum_i P(B\mid A_i)P(A_i)}
$$

## 4.3 확률변수(random variable)와 분포의 표현

* **확률변수** $X$: 결과 $\omega\in\Omega$를 실수로 대응시키는 함수 $X(\omega)$
* **이산형(discrete)**: 값이 셀 수 있음 ($0,1,2,\dots$ 등)
* **연속형(continuous)**: 구간에서 값을 가짐 ($\mathbb{R}$의 일부)

### 4.3.1 PMF(확률질량함수) — 이산형
$$
p_X(x)=P(X=x)
$$
성질: $p_X(x)\ge 0$, $\sum_x p_X(x)=1$

### 4.3.2 PDF(확률밀도함수) — 연속형
연속형에서 $P(X=x)=0$이고, 구간확률은
$$
P(a\le X\le b)=\int_a^b f_X(x)\,dx
$$
성질: $f_X(x)\ge 0$, $\int_{-\infty}^{\infty} f_X(x)\,dx=1$

### 4.3.3 CDF(누적분포함수) — 공통
$$
F_X(x)=P(X\le x)
$$
* 이산형: $F_X(x)=\sum_{t\le x} p_X(t)$
* 연속형(미분 가능하면):  
  $$f_X(x)=F_X'(x)$$

## 4.4 기대값, 분산, 공분산(핵심 요약치)

### 4.4.1 기대값(expected value)
* 이산형:
  $$
  \mathbb{E}[X]=\sum_x x\,p_X(x)
  $$
* 연속형:
  $$
  \mathbb{E}[X]=\int_{-\infty}^{\infty} x\,f_X(x)\,dx
  $$

**선형성(linearity)**:
$$
\mathbb{E}[aX+b]=a\mathbb{E}[X]+b,\qquad
\mathbb{E}[X+Y]=\mathbb{E}[X]+\mathbb{E}[Y]
$$

### 4.4.2 분산(variance)과 표준편차
$$
\mathrm{Var}(X)=\mathbb{E}\big[(X-\mu)^2\big],\quad \mu=\mathbb{E}[X]
$$
계산에 유용한 형태:
$$
\mathrm{Var}(X)=\mathbb{E}[X^2]-\big(\mathbb{E}[X]\big)^2
$$
표준편차:
$$
\mathrm{SD}(X)=\sqrt{\mathrm{Var}(X)}
$$

### 4.4.3 공분산/상관(다변수 기초)
$$
\mathrm{Cov}(X,Y)=\mathbb{E}\big[(X-\mu_X)(Y-\mu_Y)\big]
$$
상관계수:
$$
\rho_{XY}=\frac{\mathrm{Cov}(X,Y)}{\sigma_X\sigma_Y}
$$
독립이면(조건 추가 필요 없이 자주 사용):
$$
X\perp Y \ \Rightarrow\ \mathrm{Cov}(X,Y)=0
$$

## 4.5 대표 이산확률분포

### 4.5.1 베르누이분포(Bernoulli)
성공/실패 1회 시행:
$$
X\sim \mathrm{Bernoulli}(p),\quad P(X=1)=p,\ P(X=0)=1-p
$$
$$
\mathbb{E}[X]=p,\qquad \mathrm{Var}(X)=p(1-p)
$$

### 4.5.2 이항분포(Binomial)
독립 시행 $n$번에서 성공 횟수:
$$
X\sim \mathrm{Binomial}(n,p)
$$
PMF:
$$
P(X=k)=\binom{n}{k}p^k(1-p)^{n-k},\quad k=0,1,\dots,n
$$
요약치:
$$
\mathbb{E}[X]=np,\qquad \mathrm{Var}(X)=np(1-p)
$$

### 4.5.3 포아송분포(Poisson)
단위 시간/공간에서 발생 횟수(평균 발생률 $\lambda$):
$$
X\sim \mathrm{Poisson}(\lambda)
$$
PMF:
$$
P(X=k)=e^{-\lambda}\frac{\lambda^k}{k!},\quad k=0,1,2,\dots
$$
요약치:
$$
\mathbb{E}[X]=\lambda,\qquad \mathrm{Var}(X)=\lambda
$$

> 참고(근사): $n$이 크고 $p$가 작으며 $\lambda=np$가 적당하면  
> $$\mathrm{Binomial}(n,p)\approx \mathrm{Poisson}(\lambda=np)$$

## 4.6 대표 연속확률분포

### 4.6.1 균등분포(Uniform)
구간 $[a,b]$에서 동일한 밀도:
$$
X\sim \mathrm{Uniform}(a,b),\quad f(x)=\frac{1}{b-a}\ (a\le x\le b)
$$
$$
\mathbb{E}[X]=\frac{a+b}{2},\qquad \mathrm{Var}(X)=\frac{(b-a)^2}{12}
$$

### 4.6.2 정규분포(Normal)
$$
X\sim \mathcal{N}(\mu,\sigma^2)
$$
PDF:
$$
f(x)=\frac{1}{\sqrt{2\pi}\sigma}\exp\left(-\frac{(x-\mu)^2}{2\sigma^2}\right)
$$

### 4.6.3 표준정규분포(Standard normal)와 표준화(z-score)
$$
Z\sim\mathcal{N}(0,1)
$$
표준화:
$$
Z=\frac{X-\mu}{\sigma}
$$
따라서 정규분포 확률을 표준정규 CDF $\Phi(\cdot)$로 계산:
$$
P(X\le x)=P\left(Z\le \frac{x-\mu}{\sigma}\right)=\Phi\left(\frac{x-\mu}{\sigma}\right)
$$

### 4.6.4 지수분포(Exponential) (자주 등장)
대기시간 모델(포아송 과정과 연결):
$$
X\sim \mathrm{Exponential}(\lambda),\quad f(x)=\lambda e^{-\lambda x}\ (x\ge 0)
$$
$$
\mathbb{E}[X]=\frac{1}{\lambda},\qquad \mathrm{Var}(X)=\frac{1}{\lambda^2}
$$
기억없음 성질(memoryless):
$$
P(X>s+t\mid X>s)=P(X>t)
$$

## 4.7 표본분포와 중심극한정리(CLT)

표본 $X_1,\dots,X_n$이 i.i.d.이고 $\mathbb{E}[X_i]=\mu$, $\mathrm{Var}(X_i)=\sigma^2<\infty$일 때 표본평균
$$
\bar{X}=\frac{1}{n}\sum_{i=1}^n X_i
$$
는 $n$이 충분히 크면 근사적으로 정규분포를 따른다:
$$
\frac{\bar{X}-\mu}{\sigma/\sqrt{n}}\ \approx\ \mathcal{N}(0,1)
$$
즉,
$$
\bar{X}\ \approx\ \mathcal{N}\left(\mu,\frac{\sigma^2}{n}\right)
$$

* 해석: 원래 분포가 정규가 아니어도(조건 하에서) 평균은 정규에 가까워진다.
* 연결: 이후 신뢰구간/가설검정에서 $\bar{X}$의 분포 근사가 핵심 도구가 된다.

## 4.8 (요약) 자주 쓰는 키워드 체크
* 사건/조건부확률/독립: $P(A\mid B)$, $P(A\cap B)$, Bayes
* 분포 표현: PMF/PDF/CDF
* 요약치: $\mathbb{E}[X]$, $\mathrm{Var}(X)$
* 대표 분포: Bernoulli, Binomial, Poisson, Uniform, Normal, Exponential
* 표준화/CLT: $Z=\frac{X-\mu}{\sigma}$, $\frac{\bar{X}-\mu}{\sigma/\sqrt{n}}\approx \mathcal{N}(0,1)$


# 5. 상관분석(correlation analysis)

상관분석은 **두 변수의 동반 변동(co-movement)**을 요약해 “함께 증가/감소하는 경향(방향)”과 “그 강도(크기)”를 수치로 나타낸다.  
기본적으로 **관계의 정도**를 보는 것이며, **인과관계(causality)를 직접 의미하지는 않는다**.

## 5.1 공분산(covariance): 함께 변하는 방향

두 변수 $X, Y$에 대해 (모집단) 공분산은
$$
\mathrm{Cov}(X,Y)=\mathbb{E}\big[(X-\mu_X)(Y-\mu_Y)\big]
$$

표본 공분산은
$$
s_{XY}=\frac{1}{n-1}\sum_{i=1}^{n}(x_i-\bar{x})(y_i-\bar{y})
$$

* $s_{XY}>0$: $X$가 평균보다 클 때 $Y$도 평균보다 큰 경향(같은 방향으로 움직임)
* $s_{XY}<0$: $X$가 커질수록 $Y$는 작아지는 경향(반대 방향)
* 한계: 공분산의 크기는 **단위(스케일)에 의존**함(예: cm vs m로 바꾸면 값이 달라짐) → “강도 비교”에 부적합

## 5.2 피어슨 상관계수(Pearson correlation): 선형 관계의 표준화된 강도

공분산을 표준편차로 나눠 단위 영향을 제거한 값이 상관계수다.

(모집단)
$$
\rho_{XY}=\frac{\mathrm{Cov}(X,Y)}{\sigma_X\sigma_Y}
$$

(표본)
$$
r=\frac{s_{XY}}{s_X s_Y}
=\frac{\sum_{i=1}^n(x_i-\bar{x})(y_i-\bar{y})}{\sqrt{\sum_{i=1}^n(x_i-\bar{x})^2}\sqrt{\sum_{i=1}^n(y_i-\bar{y})^2}}
$$

### 성질(중요)
* $-1\le r\le 1$
* $r=1$: 완전한 양의 **선형** 관계, $r=-1$: 완전한 음의 선형 관계
* $r=0$: **선형 관계가 약함**을 시사(단, 비선형 관계는 존재할 수 있음)
* 대칭성: $r(X,Y)=r(Y,X)$
* 선형변환 불변성(일부): $r(aX+b,\,cY+d)=\mathrm{sign}(ac)\,r(X,Y)$ ($a,c\neq 0$)

### 해석 메모(실무 감각)
* “크다/작다”는 분야·맥락 의존(표본 크기, 측정오차, 연구설계에 따라 달라짐).
* 상관은 항상 **산점도(scatter plot)**로 형태(선형/비선형), 이상치(outlier), 군집(clustering)을 함께 확인하는 것이 안전.

## 5.3 스피어만 순위상관(Spearman rank correlation): 단조(monotonic) 관계

스피어만 상관은 값 자체 대신 **순위(rank)**로 상관을 계산한다.  
즉, “$X$가 커질수록 $Y$가 대체로 커지는가/작아지는가” 같은 **단조 관계**에 유용하며 이상치 영향이 상대적으로 작다.

정의: $R(X)$, $R(Y)$를 각각의 순위로 두면
$$
\rho_s=\mathrm{Corr}(R(X),R(Y))
$$

동점(tie)이 없을 때 자주 쓰는 계산식:
* 각 관측치의 순위 차이를 $d_i=R(x_i)-R(y_i)$라 하면
$$
\rho_s = 1-\frac{6\sum_{i=1}^{n} d_i^2}{n(n^2-1)}
$$

> 동점이 있으면 위의 단순식은 정확하지 않을 수 있어, 일반적으로는 “순위로 바꾼 뒤 피어슨 상관”으로 계산한다.

## 5.4 상관계수의 검정과 신뢰구간(기본)

### 5.4.1 피어슨 상관의 유의성 검정(대표 공식)
가설:
* $H_0:\rho=0$
* $H_1:\rho\ne 0$ (또는 단측)

(정규성/선형성 가정 하에서) 검정통계량:
$$
t = r\sqrt{\frac{n-2}{1-r^2}}
$$
자유도 $n-2$인 t-분포를 따른다:
$$
t\sim t_{n-2}\quad (H_0\ \text{하에서})
$$

### 5.4.2 상관의 신뢰구간(피셔 z 변환, 자주 사용)
피셔 변환:
$$
z=\frac{1}{2}\ln\left(\frac{1+r}{1-r}\right)
$$
근사적으로
$$
z \approx \mathcal{N}\left(\frac{1}{2}\ln\left(\frac{1+\rho}{1-\rho}\right),\ \frac{1}{n-3}\right)
$$
따라서 $z$에서 구간을 만든 뒤 역변환하여 $\rho$의 신뢰구간을 만든다:
$$
r=\frac{e^{2z}-1}{e^{2z}+1}
$$

> 표본이 작거나 분포가 сильно 비정규/이상치가 많으면 해석이 왜곡될 수 있어, 부트스트랩으로 상관의 신뢰구간을 구하기도 한다.

## 5.5 해석 시 자주 놓치는 포인트(체크리스트)

### (1) 선형 vs 비선형
* 피어슨 $r$은 **선형 관계** 강도에 초점.
* 예: U자형 관계는 $r\approx 0$일 수 있다 → 산점도 확인 + 필요시 비선형 모델/변환 고려.

### (2) 이상치(outlier)의 영향
* 피어슨 상관은 이상치 1~2개에도 크게 변할 수 있다.
* 대안: 스피어만, 켄달 타우(Kendall’s $\tau$), 강건 상관(robust correlation) 고려.

### (3) 범위 제한(range restriction)
* $X$ 또는 $Y$의 변동 범위가 인위적으로 좁으면 상관이 작아질 수 있다(예: 상위권 학생만 분석).

### (4) 표본 크기와 “유의하지만 작음”
* $n$이 매우 크면 작은 상관도 유의해질 수 있음 → **효과크기(상관의 크기)와 실질적 의미**를 함께 본다.

### (5) 집단 혼합(교란)과 심슨의 역설(Simpson’s paradox)
* 전체에서는 양의 상관인데, 집단별로는 음의 상관(또는 그 반대) 가능.
* 해결: 집단을 분리해 산점도/상관을 보고, 필요하면 **부분상관(partial correlation)** 또는 회귀로 통제.

## 5.6 상관과 인과: 반드시 구분

상관은 인과를 보장하지 않는다. 다음 가능성을 항상 점검한다.

1. **역인과(reverse causality)**: $Y\rightarrow X$
2. **교란(confounding)**: 제3변수 $Z$가 $X,Y$ 모두에 영향
3. **공통 원인(common cause)**, 선택편향(selection bias), 측정오류 등

### 부분상관(partial correlation) (개념 소개)
$Z$를 통제한 $X$와 $Y$의 상관(선형 통제 관점):
$$
r_{XY\cdot Z}=\frac{r_{XY}-r_{XZ}r_{YZ}}{\sqrt{(1-r_{XZ}^2)(1-r_{YZ}^2)}}
$$
* 해석: $Z$의 선형 효과를 제거한 뒤 남는 $X,Y$의 선형 연관

> 메모: “통제”는 인과를 자동으로 보장하지 않는다(통제 변수 선택 자체가 가정).

## 5.7 여러 변수의 상관: 상관행렬과 시각화

변수가 $p$개이면 상관계수를 모은 **상관행렬** $\mathbf{R}$을 만든다.
* 대각원소: 1
* 대칭행렬: $r_{jk}=r_{kj}$

실무에서 자주 쓰는 출력/점검:
* 상관행렬 표 + 히트맵(heatmap)
* 산점도 행렬(pair plot)
* 다중비교 이슈: 많은 쌍을 동시에 검정하면 거짓양성 증가 → Bonferroni, FDR 등 고려

## 5.8 (요약) 언제 무엇을 쓰나
* **연속형, 선형 관계가 핵심**: 피어슨 상관 $r$
* **순위/단조 관계, 이상치에 덜 민감**: 스피어만 $\rho_s$ (또는 켄달 $\tau$)
* **교란을 통제하고 싶음(기초적)**: 부분상관 $r_{XY\cdot Z}$ (또는 회귀로 확장)
* 항상: 수치 + 산점도 + 데이터 품질(이상치/결측/범위 제한) 동시 점검

# 6. 회귀분석(regression analysis)

회귀분석은 **종속변수 $Y$**를 **독립변수(설명변수) $X$**로 설명하고(관계 추정), 새로운 $X$가 주어졌을 때 $Y$를 예측하는 방법이다. 핵심은 (1) 평균관계 $\mathbb{E}[Y\mid X]$의 형태를 정하고, (2) 데이터를 이용해 계수를 추정하며, (3) 가정 점검과 해석/예측을 수행하는 것이다.

## 6.1 단순선형회귀(simple linear regression) 모형

관측치 $i=1,\dots,n$에 대해 단순선형회귀는 다음과 같이 둔다.
$$
Y_i=\beta_0+\beta_1 X_i+\varepsilon_i
$$

* $Y_i$: 종속변수(설명/예측 대상)
* $X_i$: 독립변수(설명변수)
* $\beta_0$: **절편(intercept)**, $X=0$일 때 평균 $Y$의 값
* $\beta_1$: **기울기(slope)**, $X$가 1 증가할 때 평균 $Y$의 변화량
* $\varepsilon_i$: 오차(error), 모형이 설명하지 못하는 부분

조건부기대값 관점에서는
$$
\mathbb{E}[Y_i\mid X_i]=\beta_0+\beta_1 X_i,\qquad Y_i=\mathbb{E}[Y_i\mid X_i]+\varepsilon_i
$$
로 이해한다.

## 6.2 최소제곱법(OLS: ordinary least squares)과 추정치

관측값과 예측값의 차이를 **잔차(residual)**라 한다.
$$
\hat{Y}_i=\hat{\beta}_0+\hat{\beta}_1 X_i,\qquad e_i=Y_i-\hat{Y}_i
$$

OLS는 잔차제곱합(RSS)을 최소화하는 $\hat{\beta}_0,\hat{\beta}_1$를 선택한다.
$$
RSS(\beta_0,\beta_1)=\sum_{i=1}^n (Y_i-(\beta_0+\beta_1X_i))^2
$$

단순회귀에서 OLS 해는 다음과 같다.
$$
\hat{\beta}_1=\frac{\sum_{i=1}^n (X_i-\bar{X})(Y_i-\bar{Y})}{\sum_{i=1}^n (X_i-\bar{X})^2},
\qquad
\hat{\beta}_0=\bar{Y}-\hat{\beta}_1\bar{X}
$$

* $\hat{\beta}_1$는 $X,Y$의 공분산을 $X$의 분산으로 나눈 형태(직관적으로 “함께 변하는 정도 / $X$의 변동”)이다.

## 6.3 변동의 분해와 결정계수($R^2$)

$Y$의 총변동(SST)은 “설명된 변동(SSR)”과 “설명되지 않은 변동(RSS)”으로 분해된다.
$$
SST=\sum_{i=1}^n (Y_i-\bar{Y})^2,\quad
SSR=\sum_{i=1}^n (\hat{Y}_i-\bar{Y})^2,\quad
RSS=\sum_{i=1}^n (Y_i-\hat{Y}_i)^2
$$
(단순회귀/OLS에서) $SST=SSR+RSS$가 성립한다.

**결정계수**는
$$
R^2=\frac{SSR}{SST}=1-\frac{RSS}{SST}
$$
* 해석: $Y$의 변동 중 모형이 설명하는 비율(0~1)
* 주의: 변수를 추가하면 $R^2$는 일반적으로 증가(또는 유지)하므로, 다중회귀에서는 **수정 $R^2$**도 함께 본다.
$$
\bar{R}^2 = 1-\frac{RSS/(n-p-1)}{SST/(n-1)}
$$
여기서 $p$는 독립변수 개수(절편 제외)이다.

## 6.4 회귀 가정(기본)과 의미

회귀에서 추정/검정이 타당하려면 보통 다음 가정을 둔다(표현은 교재/상황에 따라 조금씩 다름).

1. **선형성(linearity)**  
    $X$와 $Y$의 평균관계가 선형으로 근사 가능:
    $$
    \mathbb{E}[Y\mid X]=\beta_0+\beta_1X
    $$

2. **독립성(independence)**  
    관측치(또는 오차)가 서로 독립(특히 시계열/패널에서 중요).

3. **등분산성(homoscedasticity)**  
    $X$ 전 구간에서 오차 분산이 일정:
    $$
    \mathrm{Var}(\varepsilon_i\mid X_i)=\sigma^2
    $$

4. **정규성(normality)** *(주로 추론에 필요)*  
    오차가 정규분포:
    $$
    \varepsilon_i\mid X_i \sim \mathcal{N}(0,\sigma^2)
    $$

또한 자주 쓰는 핵심 조건으로 **외생성(평균 0 오차)**을 둔다:
$$
\mathbb{E}[\varepsilon_i\mid X_i]=0
$$
이는 “$X$가 오차와 체계적으로 연관되지 않는다”는 뜻이며, 성립하지 않으면(누락변수, 역인과, 측정오차 등) 계수 해석이 왜곡될 수 있다.

## 6.5 추론(검정/신뢰구간) 기초: t-검정과 F-검정

### 6.5.1 오차분산 추정과 표준오차
오차분산의 추정치는
$$
\hat{\sigma}^2=\frac{RSS}{n-2}
$$
(단순회귀에서 자유도는 $n-2$)

$\hat{\beta}_1$의 표준오차는
$$
SE(\hat{\beta}_1)=\sqrt{\frac{\hat{\sigma}^2}{\sum_{i=1}^n (X_i-\bar{X})^2}}
$$
(절편의 표준오차도 존재하나, 입문에서는 기울기 중심으로 다루는 경우가 많다.)

### 6.5.2 회귀계수 유의성(t-검정)
대표적으로
$$
H_0:\beta_1=0,\qquad H_1:\beta_1\ne 0
$$
검정통계량:
$$
t=\frac{\hat{\beta}_1-0}{SE(\hat{\beta}_1)} \sim t_{n-2}\quad (H_0\ \text{하에서})
$$

### 6.5.3 기울기 신뢰구간
유의수준 $\alpha$에서
$$
\hat{\beta}_1 \pm t_{1-\alpha/2,\ n-2}\cdot SE(\hat{\beta}_1)
$$

### 6.5.4 모형 전체 유의성(F-검정) (개념)
“설명변수가 하나라도 유의한가”를 검정하는 방식(다중회귀에서 특히 중요). 단순회귀에서는 $F=t^2$ 관계가 성립한다.

## 6.6 예측(prediction)과 구간: 평균반응 vs 개별값

새로운 값 $X=x_0$에서의 예측은
$$
\hat{Y}(x_0)=\hat{\beta}_0+\hat{\beta}_1 x_0
$$

* **평균반응(conditional mean)**에 대한 신뢰구간: $\mathbb{E}[Y\mid X=x_0]$의 불확실성
* **개별 관측값**에 대한 예측구간: 새로운 $Y_{new}$의 변동까지 포함하므로 더 넓다

(정확한 공식은 교재마다 표기가 다를 수 있어, 입문 단계에서는 “예측구간이 신뢰구간보다 넓다”는 점을 우선 기억하는 것이 실무적으로 중요하다.)

## 6.7 잔차진단(모형 점검) 체크리스트

* **잔차-적합값 플롯**: 선형성/등분산성 위반(곡선 패턴, 깔때기 모양) 점검
* **Q–Q plot**: 오차 정규성의 큰 위반 여부 점검(추론 목적)
* **이상치/영향점**:
  * 이상치(outlier): $Y$ 방향으로 특이한 점
  * 레버리지(leverage): $X$가 특이한 점
  * 영향점(influential): 추정계수에 큰 영향을 주는 점(Cook’s distance 등)

## 6.8 다중회귀(multiple regression) 맛보기

독립변수가 여러 개면
$$
Y_i=\beta_0+\beta_1X_{1i}+\cdots+\beta_pX_{pi}+\varepsilon_i
$$

* $\beta_j$의 해석은 “**다른 변수들을 고정했을 때** $X_j$가 1 증가하면 $Y$의 평균이 $\beta_j$만큼 변화”로 바뀐다(부분효과).
* 주의: 독립변수 간 강한 상관(다중공선성)이 있으면 표준오차가 커져 추론이 불안정해질 수 있다.

# 7. 추론통계(inferential statistics)

추론통계는 **표본(sample)**으로부터 **모집단(population)**의 모수(평균 $\mu$, 분산 $\sigma^2$, 비율 $p$ 등)를 **추정**하고, 그 추정의 불확실성을 **정량화**(신뢰구간)하거나 **가설을 검정**하는 방법론이다.

## 7.1 가설검정의 기초

### 7.1.1 핵심 용어 정리
* **통계적 가설(statistical hypothesis)**: 모집단에 대한 주장(모수/분포에 대한 진술).
* **귀무가설(null hypothesis)** $H_0$: 차이/효과가 없다는 기준 가설(예: $\mu=\mu_0$).
* **대립가설(alternative hypothesis)** $H_1$: 차이/효과가 있다는 가설(예: $\mu\ne\mu_0$, $\mu>\mu_0$ 등).
* **유의수준(significance level)** $\alpha$: $H_0$가 참일 때도 기각할 “허용 확률”(제1종 오류 한계).
* **검정통계량(test statistic)**: 표본에서 계산되는 판단 기준 값(표준화된 형태가 많음).
* **p-value**: $H_0$ 하에서 관측된 검정통계량 값(또는 그보다 더 극단적인 값)이 나올 확률.
* **기각역(rejection region)**: 유의수준 $\alpha$에서 $H_0$를 기각하는 검정통계량의 영역.
* **제1종 오류(Type I error)**: $H_0$가 참인데 기각(거짓 양성). 확률은 $\alpha$로 통제.
* **제2종 오류(Type II error)**: $H_0$가 거짓인데 기각 못함(거짓 음성). 확률은 $\beta$.
* **검정력(power)**: $1-\beta$. 실제로 효과가 있을 때 이를 잡아낼 확률.

### 7.1.2 단측/양측 검정
* **양측검정(two-sided)**: 차이가 “있다”를 검정(예: $H_1:\mu\ne\mu_0$).
* **단측검정(one-sided)**: 방향이 정해진 차이를 검정(예: $H_1:\mu>\mu_0$ 또는 $\mu<\mu_0$).
* 실무 원칙: 방향이 사전에 연구질문/설계로 정당화되지 않으면 양측을 기본으로 둔다.

### 7.1.3 가설검정의 표준 절차(워크플로우)
1. 가설 설정: $H_0$, $H_1$ 명시
2. 유의수준 선택: $\alpha$ (예: 0.05)
3. 검정통계량 선택 및 계산: $T(\text{data})$
4. 분포 가정 하에서 p-value 계산 또는 임계값(critical value)과 비교
5. 결론: “기각/기각하지 않음” + 효과크기/신뢰구간으로 실질적 의미 보고

> 메모: “$H_0$를 기각하지 못함”은 “$H_0$가 참임을 증명”이 아니다(정보 부족일 수 있음).

### 7.1.4 p-value 해석에서 자주 생기는 오해
* p-value는 $P(H_0\mid \text{data})$가 아니다.
* p-value가 작다고 효과가 “크다”는 뜻이 아니다(표본 크기 $n$이 크면 작은 효과도 유의해질 수 있음).
* p-value가 크다고 효과가 “없다”는 뜻도 아니다(검정력이 낮을 수 있음).

## 7.2 추정(estimation)과 신뢰구간(confidence interval)

### 7.2.1 점추정(point estimation)
모수 $\theta$에 대한 추정치를 $\hat{\theta}$로 둔다(예: $\hat{\mu}=\bar{X}$, $\hat{p}=\frac{1}{n}\sum D_i$).

**표준오차(standard error, SE)**는 추정치의 표본변동(불확실성)을 의미한다.
예: 평균의 표준오차(모집단 분산 $\sigma^2$가 알려져 있거나 근사적으로 사용 가능할 때)
$$
SE(\bar{X})=\frac{\sigma}{\sqrt{n}}
$$
실무에서는 $\sigma$ 대신 $s$를 사용해
$$
SE(\bar{X})\approx\frac{s}{\sqrt{n}}
$$
로 두는 경우가 많다.

### 7.2.2 신뢰구간의 기본 형태
대부분의 신뢰구간은
$$
\text{추정치} \pm (\text{임계값})\times(\text{표준오차})
$$
꼴이다.

예: (근사적으로) 정규를 이용하는 평균의 $100(1-\alpha)\%$ 신뢰구간
$$
\bar{X}\pm z_{1-\alpha/2}\cdot \frac{\sigma}{\sqrt{n}}
$$
* 여기서 $z_{1-\alpha/2}$는 표준정규분포의 분위수(예: 95%면 $z_{0.975}\approx1.96$).

> 연결: 많은 검정은 “신뢰구간에 $H_0$의 값이 포함되는가?”로도 동일한 결론을 낸다(특정 조건 하에서).

## 7.3 표본분포, 중심극한정리(CLT), 표준화

표본평균의 표본분포는 추론의 핵심이다. $X_1,\dots,X_n$이 i.i.d.이고 $\mathbb{E}[X_i]=\mu$, $\mathrm{Var}(X_i)=\sigma^2$이면
$$
\bar{X}=\frac{1}{n}\sum_{i=1}^n X_i,\qquad \mathbb{E}[\bar{X}]=\mu,\qquad \mathrm{Var}(\bar{X})=\frac{\sigma^2}{n}
$$
$n$이 충분히 크면(조건 하에)
$$
\frac{\bar{X}-\mu}{\sigma/\sqrt{n}}\approx \mathcal{N}(0,1)
$$
따라서 검정통계량은 보통 “(추정치 − 가정된 값) / 표준오차” 형태로 만든다.

## 7.4 대표적인 가설검정 예시(형식 익히기)

### 7.4.1 모평균 검정: $\sigma$를 안다고 가정(z-검정)
가설:
$$
H_0:\mu=\mu_0,\qquad H_1:\mu\ne \mu_0
$$
검정통계량:
$$
Z=\frac{\bar{X}-\mu_0}{\sigma/\sqrt{n}}
$$
$H_0$ 하에서 $Z\sim\mathcal{N}(0,1)$.  
양측검정이면 p-value는
$$
p=2\left(1-\Phi(|z_{\text{obs}}|)\right)
$$

### 7.4.2 모평균 검정: $\sigma$를 모르는 경우(t-검정)
표준오차에 $s$를 사용:
$$
T=\frac{\bar{X}-\mu_0}{s/\sqrt{n}}
$$
$H_0$ 하에서
$$
T\sim t_{n-1}
$$
(정규성 가정이 강할수록 정확, $n$이 크면 근사적으로 견고해지는 경우가 많음).

### 7.4.3 모비율 검정(근사 z-검정)
성공확률 $p$에 대해 표본비율 $\hat{p}$를 쓰면(큰 표본에서 근사):
$$
Z=\frac{\hat{p}-p_0}{\sqrt{p_0(1-p_0)/n}}
$$
* 근사 조건 예: $np_0$, $n(1-p_0)$가 충분히 클 것(경험적으로 5~10 이상 등).

## 7.5 효과크기(effect size)와 “실질적 유의성”

유의확률(p-value)은 “우연으로 보기 어려움”을 말해주지만, 효과가 얼마나 큰지(실무적 의미)는 별개다. 보고 시 권장:
* 추정치 + 신뢰구간
* 표준화된 효과크기(상황에 맞는 지표)
    * 평균 차이 상황에서(개념) 표준화 차이:
      $$
      d=\frac{\bar{x}_1-\bar{x}_2}{s_{\text{pooled}}}
      $$
* 표본 크기 $n$과 데이터 품질(이상치/결측/가정 위반 가능성)

## 7.6 검정력(power)과 표본수(n) 설계(개념)

검정력은 대립가설이 참일 때 $H_0$를 기각할 확률이다. 일반적으로
* 효과크기가 클수록 power $\uparrow$
* 표본수가 클수록 power $\uparrow$ (표준오차 $\downarrow$)
* 유의수준 $\alpha$를 작게 잡을수록(더 엄격) power $\downarrow$ 경향

검정력 함수의 개념적 표기:
$$
\text{Power}(\theta)=P(\text{reject }H_0\mid \theta)
$$
실무에서는 목표 power(예: 0.8)를 정하고 필요한 $n$을 역으로 계산하는 **power analysis**를 수행한다.

## 7.7 (실무 체크) 가정 점검과 다중비교

* **가정 점검**: 독립성, 분포 형태(심한 비정규/이상치), 등분산성(두 집단 비교 등), 표본설계(층화/가중치).
* **다중비교(multiple comparisons)**: 여러 가설을 동시에 검정하면 거짓양성 누적이 커짐.
    * 보정 예: Bonferroni, FDR(상황에 따라 선택)
* **보고 권장 포맷**: “추정치(단위) + 95% CI + p-value + 효과크기 + 가정/제한사항”


# 8. 평균 차이 검정

평균 차이 검정은 “집단(또는 조건) 간 평균이 같은가?”를 통계적으로 판단하는 절차다.  
기본 아이디어는 **관측된 평균 차이**를 **표본변동(표준오차)**으로 나눈 **표준화된 차이**(t 또는 F)를 보고, 그 값이 우연으로 설명되기 어려운지(p-value) 판단하는 것이다.

## 8.1 t검정(t-test)

t검정은 (대체로) **정규성** 또는 **표본 크기가 충분히 커서 CLT가 작동**하는 상황에서 평균에 대한 가설을 검정한다.

### 8.1.1 공통 가정과 체크포인트
* **독립성**: 관측치가 서로 독립(표본설계에 따라 위반 가능).
* **정규성(엄밀)**: 특히 표본이 작을 때 중요. 큰 표본이면 비교적 완화됨.
* **등분산성(독립표본 t에서 선택적)**: 두 집단 분산이 같다고 볼 수 있는가?
* 실무 권장: 평균·표준편차 + 박스플롯/히스토그램 + 이상치 점검을 함께 수행.

### 8.1.2 일표본 t검정(one-sample t-test)
표본평균이 특정 기준값 $\mu_0$와 다른지 검정.

* 가설(양측 예):
    $$
    H_0:\mu=\mu_0,\qquad H_1:\mu\ne\mu_0
    $$
* 검정통계량:
    $$
    t=\frac{\bar{x}-\mu_0}{s/\sqrt{n}},\qquad t\sim t_{n-1}\ (H_0\ \text{하에서})
    $$
* 신뢰구간(평균):
    $$
    \bar{x}\pm t_{1-\alpha/2,\ n-1}\cdot \frac{s}{\sqrt{n}}
    $$

### 8.1.3 독립표본 t검정(independent samples t-test)
두 독립 집단의 평균 차이 $\mu_1-\mu_2$를 검정.

#### (1) 등분산 가정(풀드 t-test)
* 가설:
    $$
    H_0:\mu_1-\mu_2=0
    $$
* 풀드 분산:
    $$
    s_p^2=\frac{(n_1-1)s_1^2+(n_2-1)s_2^2}{n_1+n_2-2}
    $$
* 검정통계량:
    $$
    t=\frac{\bar{x}_1-\bar{x}_2}{s_p\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}},\qquad t\sim t_{n_1+n_2-2}
    $$

#### (2) 등분산 가정이 어려울 때(Welch t-test, 실무 기본값으로 흔함)
* 검정통계량:
    $$
    t=\frac{\bar{x}_1-\bar{x}_2}{\sqrt{\frac{s_1^2}{n_1}+\frac{s_2^2}{n_2}}}
    $$
* 자유도는 Welch–Satterthwaite 근사로 계산(소프트웨어가 자동 처리).

### 8.1.4 대응표본 t검정(paired samples t-test)
동일 대상의 전/후, 매칭된 쌍처럼 **쌍으로 연결된 자료**에서 평균 변화(차이)의 평균이 0인지 검정.

* 각 쌍의 차이 $d_i=x_{i,\text{after}}-x_{i,\text{before}}$를 정의.
* 가설:
    $$
    H_0:\mu_d=0
    $$
* 검정통계량:
    $$
    t=\frac{\bar{d}-0}{s_d/\sqrt{n}},\qquad t\sim t_{n-1}
    $$
* 핵심: “두 표본”이 아니라 “차이값 한 표본” 문제로 바뀐다.

### 8.1.5 효과크기(effect size)와 보고
유의성(p-value)과 별개로 “차이가 얼마나 큰가”를 같이 보고하는 것이 권장된다.
* (독립표본) Cohen’s $d$ (대표 형태):
    $$
    d=\frac{\bar{x}_1-\bar{x}_2}{s_p}
    $$
* (대응표본) 표준화 변화량 예: $d_z=\frac{\bar{d}}{s_d}$ (맥락에 따라 정의가 다를 수 있음)

보고 예시(형식): 평균차(단위) + 95% CI + p-value + 효과크기.

## 8.2 분산분석(ANOVA)

ANOVA는 **2개 이상 집단 평균 차이**를 한 번에 검정하는 방법이다.  
기본 논리는 “집단 간 변동 / 집단 내 변동” 비율이 충분히 큰가를 보는 것이다.

### 8.2.1 일원분산분석(one-way ANOVA)
요인(집단) 1개, 집단 수 $k$, 전체 표본 수 $n$.

* 가설:
    $$
    H_0:\mu_1=\mu_2=\cdots=\mu_k,\qquad H_1:\text{적어도 하나는 다름}
    $$
* 변동의 분해:
    $$
    SST=\sum_{i=1}^{n}(y_i-\bar{y})^2,\quad
    SSB=\sum_{j=1}^{k} n_j(\bar{y}_j-\bar{y})^2,\quad
    SSW=\sum_{j=1}^{k}\sum_{i=1}^{n_j}(y_{ij}-\bar{y}_j)^2
    $$
    $$
    SST=SSB+SSW
    $$
* 평균제곱(mean square):
    $$
    MSB=\frac{SSB}{k-1},\qquad MSW=\frac{SSW}{n-k}
    $$
* F-통계량:
    $$
    F=\frac{MSB}{MSW}\sim F_{k-1,\ n-k}\ (H_0\ \text{하에서})
    $$

### 8.2.2 이원분산분석(two-way ANOVA)
요인 2개(예: 처리 A의 수준 $a$개, 처리 B의 수준 $b$개)에서
* **주효과(main effect)**: 요인 A만의 평균 차이, 요인 B만의 평균 차이
* **상호작용효과(interaction effect)**: A의 효과가 B 수준에 따라 달라지는지

모형의 한 표현(오차항 포함):
$$
Y_{ijk}=\mu+\alpha_i+\beta_j+(\alpha\beta)_{ij}+\varepsilon_{ijk}
$$
각 효과에 대해 별도의 F-검정을 수행한다(설계/불균형 여부에 따라 제곱합 타입 선택이 달라질 수 있음).

### 8.2.3 ANOVA의 가정(핵심)
* 독립성
* 정규성(오차의 정규성)
* 등분산성(집단별 분산이 유사)

진단(실무):
* 잔차-적합값 플롯으로 등분산성 점검
* Q–Q plot으로 정규성 큰 위반 여부 점검
* 등분산이 심하게 깨지면 Welch ANOVA 등 대안을 고려

### 8.2.4 사후검정(post-hoc test)과 다중비교
ANOVA에서 $H_0$를 기각해도 “어느 집단끼리 다른지”는 추가 비교가 필요하다.
* 대표 사후검정: Tukey HSD(등분산·동표본수에 강점), Bonferroni 보정 t-비교 등
* 다중비교 문제: 비교 횟수가 많을수록 거짓양성 증가 → 보정 절차 포함이 일반적

### 8.2.5 효과크기(ANOVA)와 보고
* 설명력(대표):
    $$
    \eta^2=\frac{SSB}{SST}
    $$
(설계에 따라 $\eta^2$, partial $\eta^2$, $\omega^2$ 등 선택)

보고 권장: $F(df_1,df_2)$, p-value, 효과크기(예: $\eta^2$), 사후검정 결과(보정 방식 명시).

## 8.3 (참고) 평균 차이 검정에서 자주 하는 실수
* **독립표본 vs 대응표본**을 잘못 선택(쌍자료를 독립으로 처리).
* 분산이 크게 다른데 풀드 t-test 사용(→ Welch 권장).
* 유의성만 보고 효과크기/신뢰구간 누락.
* 여러 집단을 t-test로 반복(보정 없이) 수행(→ ANOVA + 사후검정 권장).

## 8.4 (대안) 가정이 약할 때의 비모수 접근(키워드)
* 독립 2집단: Mann–Whitney U(=Wilcoxon rank-sum)
* 대응 2조건: Wilcoxon signed-rank
* 3집단 이상: Kruskal–Wallis(일원 ANOVA의 비모수 대안)

(분포 형태/척도/연구질문에 따라 “평균”이 아니라 “중앙값/순위 차이”를 검정하는 해석으로 바뀔 수 있음.)


# 9. 범주형 자료 분석 및 기타 검정

범주형 자료(명목/서열)에서는 평균·분산보다 **빈도/비율**과 **교차표(contingency table)**가 핵심이다.  
이 절에서는 (1) 카이제곱 계열 검정, (2) 작은 표본에서의 정확검정, (3) 범주형 효과크기, (4) 분포 가정이 약할 때 쓰는 **비모수 검정**을 정리한다.

## 9.1 카이제곱 검정(chi-square test) 개요
카이제곱 검정은 “관측도수(observed counts)와 기대도수(expected counts)의 차이”를 이용한다.

일반 형태(공통):
* 관측도수: $O$
* 기대도수: $E$ (귀무가설 $H_0$ 하에서의 기대 빈도)
* 검정통계량:
    $$
    \chi^2=\sum \frac{(O-E)^2}{E}
    $$

### 9.1.1 전제/주의사항(실무에서 중요)
* 관측치는 **독립**(대응자료/반복측정이면 별도 방법 필요: McNemar, Cochran’s Q 등).
* 기대도수 $E$가 너무 작으면 근사가 부정확할 수 있음.
    * 경험칙: 대부분의 셀에서 $E\ge 5$ 권장(상황에 따라 $E\ge 1$ 및 “$E<5$ 셀 비율 제한” 같은 기준도 사용).
* 희귀 범주는 **범주 병합** 또는 **정확검정(Fisher)** 고려.
* 유의성(p-value)만 말고 **효과크기(Cramér’s V 등)**를 함께 보고하는 것이 권장.

## 9.2 적합도 검정(goodness-of-fit test)
하나의 범주형 변수에서, 관측 분포가 특정 기대 분포와 일치하는지 검정한다.

### 9.2.1 설정
범주가 $k$개이고, 표본 크기가 $n$일 때
* 관측도수: $O_1,\dots,O_k$ (합이 $n$)
* 귀무가설: $H_0: (p_1,\dots,p_k)$가 미리 정해진 값(또는 이론에서 주어진 값)
* 기대도수:
    $$
    E_i = n p_i
    $$

### 9.2.2 검정통계량과 자유도
$$
\chi^2=\sum_{i=1}^k \frac{(O_i-E_i)^2}{E_i}
$$
* $H_0$ 하에서 근사적으로
    $$
    \chi^2 \sim \chi^2_{k-1}
    $$
* 단, $p_i$를 데이터로 추정(모수 적합)했다면 자유도는 감소:
    $$
    df = (k-1)-(\text{추정한 모수 개수})
    $$

### 9.2.3 잔차(residual)로 “어디가 다른가” 보기
유의하면 “어느 범주가 많이/적게 나왔는지”를 잔차로 확인한다.
* Pearson 잔차:
    $$
    r_i=\frac{O_i-E_i}{\sqrt{E_i}}
    $$

## 9.3 독립성 검정(test of independence) / 동질성 검정(test of homogeneity)
두 범주형 변수가 관련 있는지(독립인지) 확인하는 표준 방법.  
실무에서는 **독립성 검정(교차표)**로 거의 통칭해 사용한다.

### 9.3.1 $r\times c$ 교차표와 기대도수
* 관측도수: $O_{ij}$ (행 $i=1,\dots,r$, 열 $j=1,\dots,c$)
* 행합: $O_{i\cdot}=\sum_{j}O_{ij}$, 열합: $O_{\cdot j}=\sum_{i}O_{ij}$, 전체합 $n$
* 독립($H_0$)이면 $P(i,j)=P(i)P(j)$이므로 기대도수:
    $$
    E_{ij}=\frac{O_{i\cdot}\,O_{\cdot j}}{n}
    $$

### 9.3.2 검정통계량과 자유도
$$
\chi^2=\sum_{i=1}^r\sum_{j=1}^c \frac{(O_{ij}-E_{ij})^2}{E_{ij}}
$$
자유도:
$$
df=(r-1)(c-1)
$$
근사적으로 $\chi^2\sim \chi^2_{df}$.

### 9.3.3 어떤 셀이 기여했는지: 표준화 잔차
* (간단) 표준화 잔차:
    $$
    z_{ij}=\frac{O_{ij}-E_{ij}}{\sqrt{E_{ij}}}
    $$
$|z_{ij}|$가 큰 셀이 전체 $\chi^2$에 크게 기여(“차이가 큰 셀”)한다.

## 9.4 범주형 관계의 효과크기(effect size)
표본이 커지면 작은 차이도 유의해질 수 있으므로, **효과크기**가 중요하다.

### 9.4.1 $\phi$ 계수(2×2)
2×2 표에서
$$
\phi=\sqrt{\frac{\chi^2}{n}}
$$

### 9.4.2 Cramér’s $V$ (일반 $r\times c$)
$$
V=\sqrt{\frac{\chi^2}{n\,(m-1)}},\qquad m=\min(r,c)
$$
* 범위: $0\le V\le 1$
* 해석의 “큰/작음”은 분야·맥락 의존(표본설계/측정오차/범주수 영향).

## 9.5 작은 표본/희귀 범주: Fisher의 정확검정(2×2)
기대도수가 너무 작은 2×2 표에서는 카이제곱 근사 대신 정확검정을 고려한다.
* 핵심 아이디어: 주변합(margins)을 고정했을 때 가능한 표들 중 “관측된 표만큼(또는 더) 극단적인 표”의 확률을 계산.
* 소프트웨어에서 `fisher.test()`(R) 등으로 수행하는 것이 일반적.

## 9.6 대응(짝) 범주형 자료: McNemar 검정(2×2, 전/후)
같은 대상의 전/후처럼 **짝지어진 이분형 결과**에서 변화가 있는지 검정한다.

2×2 표에서 불일치 셀을 $b, c$라 하면(한쪽에서만 바뀐 경우):
* 귀무가설: 변화 방향이 대칭($b=c$)
* 근사 카이제곱 형태(연속성 보정 없이):
    $$
    \chi^2=\frac{(b-c)^2}{b+c}\sim \chi^2_{1}
    $$
(작은 표본이면 정확한 McNemar 검정도 사용)

## 9.7 비모수 검정(nonparametric tests) 개요
비모수 검정은 대개
* 정규성 가정이 약하거나
* 이상치가 많거나
* 척도가 **서열척도(ordinal)**이거나
* 평균 대신 **중앙값/순위 기반 위치**를 비교하고 싶을 때
사용한다.

> 메모: “비모수”는 “표본이 작아도 항상 안전”을 뜻하진 않으며, **독립성/대응 여부** 같은 설계 가정은 여전히 중요하다.

## 9.8 두 집단 비교(독립): Mann–Whitney U / Wilcoxon rank-sum
두 독립 집단($n_1$, $n_2$)의 “분포 위치”가 같은지(자주 ‘중앙값 차이’로 오해되지만, 엄밀히는 분포 형태 가정에 따라 의미가 달라짐) 검정한다.

### 9.8.1 절차(핵심)
1. 두 집단 데이터를 합쳐 **순위(rank)**를 매김(동점은 평균순위).
2. 한 집단(예: 집단 1)의 순위합 $R_1$ 계산.

### 9.8.2 U 통계량(대표 정의 중 하나)
$$
U_1 = R_1-\frac{n_1(n_1+1)}{2}
$$
또는 $U_2$를 정의하며 $U_1+U_2=n_1n_2$.

표본이 충분히 크면 정규근사를 사용(동점 보정 포함 가능). 실제 구현은 소프트웨어가 처리하는 경우가 많다.

### 9.8.3 해석 포인트
* “평균 차이” 검정이 아니라 “순위 기반 차이” 검정.
* 두 집단의 분포 모양이 유사할 때는 위치(중앙값) 차이로 해석이 더 자연스럽다.

## 9.9 두 조건 비교(대응): Wilcoxon signed-rank
같은 대상의 전/후처럼 대응 자료에서 차이의 중앙값이 0인지 검정한다.

### 9.9.1 절차(요약)
1. 차이 $d_i = x_{i,after}-x_{i,before}$
2. $d_i=0$은 제외
3. $|d_i|$에 순위를 매기고, 부호를 붙여 순위합을 비교

### 9.9.2 장점/주의
* 이상치에 t-검정보다 덜 민감한 편.
* 차이 분포가 대칭(symmetric)일 때 해석이 매끄럽다(상황에 따라 중요).

## 9.10 3집단 이상(독립): Kruskal–Wallis 검정
일원 ANOVA의 비모수 대안으로, $k$개 독립 집단의 분포가 같은지 검정한다.

### 9.10.1 순위 기반 통계량(대표 형태)
전체 $n$개 관측치를 합쳐 순위를 매기고, 집단 $j$의 순위합을 $R_j$, 크기를 $n_j$라 하면:
$$
H=\frac{12}{n(n+1)}\sum_{j=1}^{k}\frac{R_j^2}{n_j}-3(n+1)
$$
근사적으로
$$
H\sim \chi^2_{k-1}
$$
(동점이 많으면 보정이 필요할 수 있음)

### 9.10.2 사후검정(post-hoc)
유의하면 “어느 집단끼리 다른지” 추가 비교가 필요하다.
* 순위 기반 쌍비교 + 다중비교 보정(Bonferroni, Holm 등)을 함께 사용.

## 9.11 (참고) 자주 쓰는 선택 가이드
* **범주형 빈도 비교**: 카이제곱(적합도/독립성)
* **2×2, 기대도수 작음**: Fisher 정확검정
* **대응 이분형(전/후)**: McNemar
* **연속/서열, 정규성 약함**
    * 독립 2집단: Mann–Whitney U(Wilcoxon rank-sum)
    * 대응 2조건: Wilcoxon signed-rank
    * 독립 3집단 이상: Kruskal–Wallis

# 10. 추가로 포함하면 좋은 입문 키워드(확장)

이 절은 “통계 입문에서 자주 마주치지만, 본문 흐름상 빠지기 쉬운” 개념들을 짧게 정리한다. 실무에서는 각 키워드가 **분석 결과의 해석·재현성·품질**에 직접 영향을 준다.

## 10.1 신뢰구간(confidence interval, CI)
**점추정치 하나만** 제시하면 불확실성이 숨겨지므로, 가능한 한 **신뢰구간**으로 함께 보고한다.

* 일반 형태:
    $$
    \text{추정치} \pm (\text{임계값})\times(\text{표준오차})
    $$

### (1) 평균의 신뢰구간
* 모분산 $\sigma^2$를 안다고 가정(또는 큰 표본 근사):
    $$
    \bar{x}\ \pm\ z_{1-\alpha/2}\cdot \frac{\sigma}{\sqrt{n}}
    $$
* $\sigma$를 모르는 경우(보통의 현실):
    $$
    \bar{x}\ \pm\ t_{1-\alpha/2,\ n-1}\cdot \frac{s}{\sqrt{n}}
    $$

### (2) 비율의 신뢰구간(근사)
표본비율 $\hat{p}$에 대해(큰 표본에서)
$$
\hat{p}\ \pm\ z_{1-\alpha/2}\cdot \sqrt{\frac{\hat{p}(1-\hat{p})}{n}}
$$
> 메모: $\hat{p}$가 0이나 1에 가깝거나 표본이 작으면 Wilson/Agresti–Coull 같은 대안을 고려.

### (3) 해석 주의
* “95% CI”는 **반복 표본추출**을 했을 때 구간이 참값을 포함하는 비율이 95%라는 뜻(한 번의 구간이 95% 확률로 참값을 포함한다는 표현은 엄밀히 다름).
* 보고 습관: **추정치(단위) + 95% CI**를 기본으로 두고, 필요 시 p-value를 보조로 제시.

## 10.2 효과크기(effect size)
p-value는 “우연으로 보기 어렵다”를 말하지만, **차이/관계가 얼마나 큰지**는 효과크기로 판단한다(실질적 유의성).

### (1) 평균 차이: Cohen’s $d$
독립 2집단에서(대표 형태)
$$
d=\frac{\bar{x}_1-\bar{x}_2}{s_p},\qquad
s_p=\sqrt{\frac{(n_1-1)s_1^2+(n_2-1)s_2^2}{n_1+n_2-2}}
$$

### (2) 상관: $r$ 또는 $r^2$
* 상관계수 $r$ 자체가 효과크기.
* $r^2$는 “선형적으로 설명되는 분산 비율”로 해석(단, 인과 의미는 아님).

### (3) ANOVA: $\eta^2$
일원분산분석에서 대표적으로
$$
\eta^2=\frac{SSB}{SST}
$$

### (4) 범주형(2×2): 오즈비(OR), 상대위험도(RR)
2×2 표를
\[
\begin{array}{c|cc}
 & Y=1 & Y=0\\ \hline
X=1 & a & b\\
X=0 & c & d
\end{array}
\]
라고 할 때
$$
OR=\frac{a/b}{c/d}=\frac{ad}{bc},\qquad
RR=\frac{a/(a+b)}{c/(c+d)}
$$

> 메모: “작다/크다” 기준은 분야 의존이므로, 가능하면 **해석 문장(단위 기반)**과 함께 제시.

## 10.3 데이터 정제(data cleaning)
분석 품질은 “모델”보다 “데이터 정제”에서 결정되는 경우가 많다.

### (1) 대표 작업
* **형식/타입 정리**: 날짜/숫자/범주형 변환, 단위 통일(예: cm↔m)
* **중복 제거**: 동일 ID·동일 레코드 중복 여부 확인
* **범위/규칙 검증**: 나이<0, 비율>1 같은 규칙 위반 탐지
* **라벨/코딩 확인**: 범주 인코딩(예: 1=남, 2=여) 문서화
* **이상치·결측치 처리**: 아래 10.4~10.5 참고
* **재현성 확보**: 정제 규칙/코드/버전 기록(“왜 이렇게 바꿨는가”가 남아야 함)

### (2) 최소 권장 산출물
* 정제 전/후 행 개수, 제거·수정된 항목 수 요약
* 주요 변수의 결측률, 이상치 후보 수
* 정제 규칙(필터, 대체값, 제외 기준) 명시

## 10.4 이상치(outlier)
이상치는 **(a) 데이터 오류**일 수도, **(b) 의미 있는 극단 사례**일 수도 있어 “자동 제거”는 위험하다.

### (1) 흔한 탐지 규칙
* z-score(대략적 점검):
    $$
    z_i=\frac{x_i-\bar{x}}{s}
    $$
    경험적으로 $|z_i|\ge 3$ 근처를 후보로 점검.
* IQR 규칙(박스플롯 기준):
    $$
    IQR=Q_3-Q_1,\quad
    Lower=Q_1-1.5\cdot IQR,\quad Upper=Q_3+1.5\cdot IQR
    $$

### (2) 처리 옵션(상황별)
* 원인 확인 후 **수정(오입력)** / **제외(측정 실패)** / **유지(진짜 극단)**  
* 강건 방법 사용: 중앙값·IQR, 절사평균, 강건 회귀 등
* 변환 고려: 로그변환 $Y=\log X$ (양수 자료에서 분포 안정화 목적)

## 10.5 결측치(missing value)
결측은 “값이 없다”가 아니라 “값이 어떤 메커니즘으로 빠졌는가”가 핵심이다.

### (1) 결측 메커니즘(용어)
* **MCAR**(완전무작위 결측): 결측이 데이터와 무관
* **MAR**(조건부 무작위 결측): 관측된 변수들을 조건으로 하면 무작위
* **MNAR**(비무작위 결측): 결측이 결측값 자체와 연관(가장 까다로움)

### (2) 기본 점검
* 변수별 결측률: $\frac{\#\text{missing}}{n}$
* 결측 패턴: 특정 집단/기간/조건에서 결측이 집중되는지(편향 가능성)

### (3) 처리 방법(대표)
* **완전사례분석(listwise deletion)**: 결측이 적고 MCAR에 가까울 때 단순
* **단순 대체(imputation)**(권장 주의):
    * 평균대체: 결측인 $x_i$를 $\bar{x}$로 대체(분산 과소추정 위험)
* **모형 기반/다중대체(MI)**: 불확실성을 반영(실무에서 자주 권장)

> 메모: 결측 처리는 추정치·표준오차·편향에 영향을 주므로, “어떤 방법을 썼는지”를 결과에 반드시 명시.

## 10.6 통계 소프트웨어 개요(SPSS, R, Python 등)
도구 선택보다 중요한 것은 **재현성(reproducibility)**과 **검증 가능성**이다.

### (1) SPSS
* 장점: GUI 중심, 설문/기초 통계 절차가 빠름
* 주의: 클릭 기반 작업은 재현이 어려울 수 있어, 출력/설정 기록이 중요

### (2) R
* 장점: 통계 방법·패키지 생태계 강함, 보고서 자동화(R Markdown/Quarto)
* 활용 예: 가설검정, 회귀, 시각화(ggplot2), 부트스트랩/베이즈 등 확장 용이

### (3) Python
* 장점: 데이터 처리(pandas), 시각화(seaborn/matplotlib), 머신러닝(scikit-learn) 연계 강함
* 활용 예: ETL → EDA → 모델링 → 배포까지 파이프라인 구성 용이

### (4) 공통 실무 체크리스트
* 데이터/코드/환경 버전 고정(패키지 버전 포함)
* 랜덤 시드(seed) 기록
* 분석 로그와 결과(표/그림)의 자동 생성(수작업 복붙 최소화)



# 11. 추가
## 11.1 경우의 수의 기본 원리(The Basic Principle of Counting)

### (1) 곱셈원리(제품법칙)
연속된 단계 1,2,…,m에서 각 단계 선택지 수가 각각 $n_1,n_2,\dots,n_m$이면 전체 경우의 수는
$$
n_1 n_2\cdots n_m
$$

### (2) 덧셈원리(합의 법칙)
서로 겹치지 않는(서로소) 경우의 수가 $n_1,\dots,n_m$이면 전체는
$$
n_1+\cdots+n_m
$$

### (3) 순열·조합(자주 쓰는 공식)
* 순열: $n$개 중 $k$개를 **순서 있게**
    $$
    {}_nP_k=\frac{n!}{(n-k)!}
    $$
* 조합: $n$개 중 $k$개를 **순서 없이**
    $$
    {n\choose k}=\frac{n!}{k!(n-k)!}
    $$

### (4) 포함-배제(Inclusion–Exclusion) (핵심 형태)
두 집합:
$$
|A\cup B|=|A|+|B|-|A\cap B|
$$
세 집합:
$$
|A\cup B\cup C|=|A|+|B|+|C|-|A\cap B|-|A\cap C|-|B\cap C|+|A\cap B\cap C|
$$

### (5) 중복조합(stars and bars로 연결)
서로 구분되는 $n$개에서 **중복 허용**하여 $k$개를 고르는 수:
$$
{n+k-1\choose k}
$$


## 11.2 정수해의 개수(The Number of Integer Solutions of Equations)

### (1) 비음이 아닌 정수해(Stars and Bars)
$$
x_1+\cdots+x_k=n,\qquad x_i\in\mathbb{Z}_{\ge 0}
$$
의 해 개수:
$$
{n+k-1\choose k-1}
$$

### (2) 양의 정수해
$$
x_1+\cdots+x_k=n,\qquad x_i\in\mathbb{Z}_{\ge 1}
$$
치환 $y_i=x_i-1$로 $y_i\ge 0$, $\sum y_i=n-k$이므로 해 개수:
$$
{n-1\choose k-1}\quad (n\ge k)
$$

### (3) 상한이 있는 경우(개념)
$$
x_1+\cdots+x_k=n,\qquad 0\le x_i\le u_i
$$
는 생성함수/포함-배제 등으로 계산한다. (실무적으로는 DP(동적계획)도 많이 사용)

### (4) 간단 예시
“사탕 10개를 3명에게(0개 가능) 나누기”:
$$
{10+3-1\choose 3-1}={12\choose 2}=66
$$


## 11.3 확률을 ‘연속인 집합함수’로 보기(Probability as a Continuous Set Function)

확률은 사건들의 집합족 $\mathcal{F}$ 위에서 정의되는 함수 $P:\mathcal{F}\to[0,1]$로 본다.

### (1) $\sigma$-대수와 확률측도
* $(\Omega,\mathcal{F})$: 표본공간과 $\sigma$-대수
* 공리: $P(\Omega)=1$, 가산가법성(서로소 $A_i$)
    $$
    P\Big(\bigcup_{i=1}^\infty A_i\Big)=\sum_{i=1}^\infty P(A_i)
    $$

### (2) 연속성(continuity) 성질
* 아래로 연속(증가열): $A_1\subset A_2\subset\cdots$, $A=\cup_i A_i$
    $$
    P(A)=\lim_{i\to\infty}P(A_i)
    $$
* 위로 연속(감소열): $A_1\supset A_2\supset\cdots$, $A=\cap_i A_i$
    $$
    P(A)=\lim_{i\to\infty}P(A_i)
    $$
    (특히 $P(A_1)<\infty$는 확률에서는 항상 만족)

### (3) 측도론적 관점의 장점
연속형 확률변수, 조건부기대값(정교한 의미), 마르코프 과정/확률과정 등을 일관된 틀에서 다룰 수 있다.


## 11.4 확률을 ‘믿음의 정도’로 보기(Probability as a Measure of Belief)

### (1) 주관적 확률(Subjective/Bayesian probability)
확률을 “불확실성에 대한 합리적 믿음”으로 해석한다.
* 사전분포(prior) $P(\theta)$
* 우도(likelihood) $P(D\mid\theta)$
* 사후분포(posterior)
    $$
    P(\theta\mid D)=\frac{P(D\mid\theta)P(\theta)}{P(D)}
    $$

### (2) 정합성(coherence)과 Dutch book 아이디어(개념)
확률 규칙(공리)을 어기면 일관된 베팅 규칙에서 확정 손실이 생길 수 있다는 논증이 “공리의 합리성”을 뒷받침한다.

### (3) 빈도주의 vs 베이즈(요약)
* 빈도주의: 반복실험에서 장기빈도 관점
* 베이즈: 관측 후 믿음 업데이트(사후분포) 관점  
실무에서는 문제(의사결정/예측/추정)에 따라 혼합적으로 사용된다.


## 11.5 교환가능 랜덤변수(Exchangeable Random Variables)

### (1) 정의
$(X_1,\dots,X_n)$이 **교환가능(exchangeable)**이면 모든 순열 $\pi$에 대해
$$
(X_1,\dots,X_n)\ \overset{d}{=}\ (X_{\pi(1)},\dots,X_{\pi(n)})
$$

### (2) i.i.d.와의 관계
* i.i.d. $\Rightarrow$ exchangeable (항상 참)
* exchangeable $\nRightarrow$ i.i.d. (일반적으로 거짓)

### (3) 핵심 직관
“순서가 중요하지 않은 대칭성”만 가정한다. 표본이 ‘조건부로 i.i.d.’인 혼합모형(mixture)로 이해되는 경우가 많다.

### (4) (참고) de Finetti 정리(이분형에서의 대표 형태, 개념)
무한 교환가능 베르누이열은 어떤 잠재변수 $\Theta$에 대해
$$
X_i\mid \Theta \ \text{i.i.d. Bernoulli}(\Theta)
$$
인 혼합으로 표현 가능하다는 결과가 유명하다(정확한 정식화는 측도론 필요).


## 11.6 기대값의 일반적 정의(General Definition of Expectation)

### (1) 측도론적 정의
확률공간 $(\Omega,\mathcal{F},P)$에서 확률변수 $X$가 적분가능이면
$$
\mathbb{E}[X]=\int_\Omega X(\omega)\,dP(\omega)
$$

### (2) 분포 기반 표현
* 이산형:
    $$
    \mathbb{E}[X]=\sum_x x\,P(X=x)
    $$
* 연속형(밀도 $f$ 존재):
    $$
    \mathbb{E}[X]=\int_{-\infty}^{\infty} x f(x)\,dx
    $$
* 일반 분포(분포측도 $P_X$):
    $$
    \mathbb{E}[g(X)]=\int_{\mathbb{R}} g(x)\,dP_X(x)
    $$

### (3) 조건부기대값(개념)
$\sigma$-대수 $\mathcal{G}$에 대한 조건부기대값은
$$
\mathbb{E}[X\mid\mathcal{G}]
$$
로 정의되며, “$\mathcal{G}$로 측정 가능한” 최적(최소제곱 의미)의 예측값으로 해석된다.


## 11.7 체비셰프 부등식과 약한 대수의 법칙(Chebyshev’s Inequality and the WLLN)

### (1) 마르코프 부등식(기본 도구)
$X\ge 0$이면
$$
P(X\ge a)\le \frac{\mathbb{E}[X]}{a}\quad (a>0)
$$

### (2) 체비셰프 부등식
분산이 유한하면
$$
P(|X-\mu|\ge \varepsilon)\le \frac{\mathrm{Var}(X)}{\varepsilon^2}
$$

### (3) 약한 대수의 법칙(WLLN; 한 표준 형태)
$X_1,\dots,X_n$ i.i.d., $\mathbb{E}[X_i]=\mu$, $\mathrm{Var}(X_i)=\sigma^2<\infty$이면
$$
\bar{X}_n \xrightarrow{P} \mu
$$
증명 흐름(요약): $\mathrm{Var}(\bar{X}_n)=\sigma^2/n$ 및 체비셰프로
$$
P(|\bar{X}_n-\mu|\ge\varepsilon)\le \frac{\sigma^2}{n\varepsilon^2}\to 0
$$

### (4) 실무적 의미
표본평균의 “오차 확률”이 $n$이 커질수록 작아진다(단, 분산 유한 등의 조건이 중요).


## 11.8 기타 부등식과 포아송 극한(Other Inequalities and a Poisson Limit Result)

### (1) Cauchy–Schwarz
$$
|\mathbb{E}[XY]|\le \sqrt{\mathbb{E}[X^2]\mathbb{E}[Y^2]}
$$

### (2) Jensen
볼록함수 $\varphi$에 대해
$$
\varphi(\mathbb{E}[X])\le \mathbb{E}[\varphi(X)]
$$
(로그, 지수 등을 다룰 때 빈번)

### (3) Hoeffding (유계 독립합의 농도; 형태만)
$X_i\in[a_i,b_i]$ 독립이면
$$
P(\bar{X}-\mathbb{E}[\bar{X}]\ge t)\le \exp\left(-\frac{2n^2 t^2}{\sum_{i=1}^n (b_i-a_i)^2}\right)
$$
(체비셰프보다 훨씬 강한(지수형) 꼬리 상계)

### (4) 포아송 극한(희귀사건의 극한)
$X_n\sim\mathrm{Binomial}(n,p_n)$이고 $n p_n\to \lambda$이면
$$
X_n \Rightarrow \mathrm{Poisson}(\lambda)
$$
즉, 큰 $n$에서 “작은 $p$”의 성공 횟수는 포아송으로 근사된다.


## 11.9 베르누이 합을 포아송으로 근사할 때의 오차 확률 상계
(Bounding the Error Probability for Poisson Approximation)

독립 베르누이 $X_i\sim\mathrm{Bernoulli}(p_i)$, 합 $W=\sum_{i=1}^n X_i$, $\lambda=\sum p_i$에 대해 $W$를 $\mathrm{Poisson}(\lambda)$로 근사한다.

### (1) 오차 척도: 총변동거리(total variation distance)
$$
d_{TV}(\mathcal{L}(W),\mathrm{Poisson}(\lambda))
=\frac{1}{2}\sum_{k=0}^{\infty}\left|P(W=k)-e^{-\lambda}\frac{\lambda^k}{k!}\right|
$$

### (2) Le Cam 부등식(대표 상계 중 하나)
$$
d_{TV}\big(\mathcal{L}(W),\mathrm{Poisson}(\lambda)\big)\ \le\ \sum_{i=1}^n p_i^2
$$
* 해석: 각 사건이 충분히 희귀($p_i$가 작음)하면 근사 오차가 작다.
* 동질 $p_i=p$이면 $\sum p_i^2=np^2=(np)p=\lambda p$로, $\lambda$가 고정이고 $p\to 0$이면 오차 $\to 0$.

### (3) 언제 유용한가
* 결함 수, 도착 수, 희귀 이벤트 카운트 등에서 이항(또는 베르누이 합)을 포아송으로 단순화할 때 근사 품질을 정량적으로 점검할 수 있다.


## 11.10 로렌츠 곡선(The Lorenz Curve)

소득/부의 불평등을 시각화·정량화하는 도구.

### (1) 정의(연속형, 누적분포 기반)
소득 변수 $X\ge 0$, 평균 $\mu>0$, CDF $F$일 때 로렌츠 곡선 $L(p)$는 (대표 표현)
$$
L(p)=\frac{1}{\mu}\int_0^p F^{-1}(u)\,du,\qquad 0\le p\le 1
$$
* $p$: 하위 $p$ 비율(인구 누적 비중)
* $L(p)$: 그들이 차지하는 소득 누적 비중

### (2) 성질
* $L(0)=0$, $L(1)=1$
* 완전평등이면 $L(p)=p$ (45도 직선)
* 불평등이 클수록 곡선이 아래로 처진다.

### (3) 지니계수(Gini; 연결)
로렌츠 곡선 아래 면적 $A=\int_0^1 L(p)\,dp$이면
$$
G=1-2A
$$
(실무에서는 표본자료로 수치적 계산)


## 11.11 ADDITIONAL TOPICS IN PROBABILITY

### 11.11.1 포아송 과정(The Poisson Process)
단위시간당 평균 발생률 $\lambda>0$를 가지는 카운팅 과정 $\{N(t)\}_{t\ge 0}$.

* 성질(정의적 특징):
    1. $N(0)=0$
    2. 독립증분: 서로 겹치지 않는 구간의 증가량이 독립
    3. 정상증분: $N(t+s)-N(s)\sim \mathrm{Poisson}(\lambda t)$
* 결과:
    $$
    P(N(t)=k)=e^{-\lambda t}\frac{(\lambda t)^k}{k!}
    $$
* 도착시간 간격(interarrival time) $T$는 지수분포:
    $$
    T\sim \mathrm{Exponential}(\lambda)
    $$

### 11.11.2 마르코프 연쇄(Markov Chains)
이산시간 마르코프 연쇄 $\{X_n\}$는
$$
P(X_{n+1}=j\mid X_n=i, X_{n-1},\dots,X_0)=P(X_{n+1}=j\mid X_n=i)=P_{ij}
$$
* 전이행렬 $P=(P_{ij})$
* $n$-단계 전이: $P^n$
* 정상분포(정지분포) $\pi$: 
    $$
    \pi=\pi P,\quad \sum_i \pi_i=1
    $$
* 실무 연결: 랜덤워크, MCMC(메트로폴리스-헤이스팅스 등), 큐잉, 신뢰성 모델

### 11.11.3 놀람·불확실성·엔트로피(Surprise, Uncertainty, and Entropy)
* 놀람(surprisal): 사건 $x$의 정보량
    $$
    I(x)=-\log p(x)
    $$
* 엔트로피(불확실성의 평균 정보량):
    $$
    H(X)=\mathbb{E}[-\log p(X)] = -\sum_x p(x)\log p(x)
    $$
(로그 밑이 2면 bit 단위)

* 교차엔트로피/상대엔트로피(KL 발산; 개념):
    $$
    D_{KL}(p\|q)=\sum_x p(x)\log\frac{p(x)}{q(x)}\ge 0
    $$

### 11.11.4 부호화 이론과 엔트로피(Coding Theory and Entropy)
* 직관: 평균 부호 길이(압축률)의 하한이 엔트로피에 의해 제한된다.
* (개념) 이상적인 무손실 부호에서 평균 코드 길이 $\bar{L}$는
    $$
    \bar{L}\ \gtrsim\ H(X)
    $$
* 응용: 데이터 압축, 통신, 통계적 모델 선택(MDL), 머신러닝의 로그우도/크로스엔트로피 손실


## 11.12 SIMULATION

### 11.12.1 Introduction
시뮬레이션(몬테카를로)은 난수 생성으로 기대값/확률/분포를 근사한다.
* 목표 예:
    $$
    \theta=\mathbb{E}[g(X)]
    $$
    를 $X^{(1)},\dots,X^{(N)}$ 샘플로
    $$
    \hat{\theta}_N=\frac{1}{N}\sum_{m=1}^N g(X^{(m)})
    $$
* 핵심 이슈: 난수 품질, 수렴(표준오차), 분산 감소

### 11.12.2 연속분포 난수 생성(General Techniques for Simulating Continuous Random Variables)
* 역변환법(inverse transform): $U\sim \mathrm{Uniform}(0,1)$이면
    $$
    X=F^{-1}(U)
    $$
* 거절표집(rejection sampling): 목표 $f$, 제안 $g$, 상수 $M$으로 $f(x)\le Mg(x)$
* 합성/혼합(composition/mixture): 혼합분포는 먼저 성분 선택 후 조건부 샘플
* 정규분포 예: Box–Muller 등(구현에 따라 Ziggurat 등도 사용)

### 11.12.3 이산분포 샘플링(Simulating from Discrete Distributions)
* 누적합 기반(CDF method): 누적확률을 만들어 $U$가 떨어지는 구간 선택
* Alias method: 범주 수가 크고 반복 샘플링이 많을 때 $O(1)$ 샘플링 가능(전처리 필요)

### 11.12.4 분산 감소 기법(Variance Reduction Techniques)
같은 샘플 수로 더 정확한 추정(표준오차 감소)을 목표로 한다.
* 대칭표본(antithetic variates): $U$와 $1-U$를 함께 사용
* 제어변수(control variates):
    알려진 기대값 $\mathbb{E}[C]$를 이용해
    $$
    g(X)-a(C-\mathbb{E}[C])
    $$
    형태로 분산을 줄임($a$는 최적화 가능)
* 층화추출(stratified sampling): 표본공간을 구간/층으로 나누고 각 층에서 균형 있게 샘플
* 중요도추출(importance sampling): 희귀사건 확률 추정에서 특히 유용
    $$
    \mathbb{E}_f[g(X)]=\mathbb{E}_h\left[g(X)\frac{f(X)}{h(X)}\right]
    $$
    (단, 가중치 폭주에 주의)
* 공통난수(common random numbers): 두 시스템/정책 비교 시 같은 난수 스트림 사용으로 비교 분산 감소